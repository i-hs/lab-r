encoding = 'UTF-8')
str(credit)
head(credit)
# C50::C5.0(train, class, trial = 1, costs = NULL)
# train : 학습 데이터 세트
# class : 학습 데이터의 레이블 (분류에 대한 정답 - 현 예제에서는 default값)
# trials, costs : 옵션 -> 성능 개선
# 학습 데이터 세트에서는 데이터의 레이블(클래스)를 제거해야 함!
credit_model <- C5.0(train_set[-17], train_set$default)
train_set <- credit[rows,]         # 학습 데이터 세트
test_set  <- credit[-rows,]        # 테스트 데이터 세트
# 학습 데이터 세트와 테스트 데이터 세트(9:1)를 준비
rows <- sample(1000, 900)
train_set <- credit[rows,]         # 학습 데이터 세트
test_set  <- credit[-rows,]        # 테스트 데이터 세트
# C50::C5.0(train, class, trial = 1, costs = NULL)
# train : 학습 데이터 세트
# class : 학습 데이터의 레이블 (분류에 대한 정답 - 현 예제에서는 default값)
# trials, costs : 옵션 -> 성능 개선
# 학습 데이터 세트에서는 데이터의 레이블(클래스)를 제거해야 함!
credit_model <- C5.0(train_set[-17], train_set$default)
# 모델을 테스트 데이터를 사용해서 평가
#stats::predict(모델, 테스트 데이터 세트)
credit_pred <- predict(credit_model, test_set[-17])
credit_model
table(credit_pred)
predict
mushroom_ripper <- JRip(type ~., mushroom)
# Decision Tree (의사 결정 나무)
rm(list = ls())
# 규칙 학습자(rule learner) 분류기
mushroom <- read.csv(file = 'mlwr/mushrooms.csv',
encoding = 'UTF-8')
str(mushroom)
head(mushroom)
table(mushroom$type)
# veil_type 변수는 모든 행이 동일한 값 - 분류 기준이 될 수 없음.
mushroom$veil_type <- NULL  # factor level이 1개인 특성(column)을 삭제
library(OneR)
# 모델 훈련
mushroom_1R <- OneR(type ~ ., data = mushroom)
mushroom_1R_cap <- OneR(type ~ cap_shape + cap_surface + cap_color,
data = mushroom)
library(RWeka)                    # 실행하기 위해서는 자바 설치 필요
mushroom_ripper <- JRip(type ~., mushroom)
mushroom_ripper
View(mushroom)
# 1. 데이터 준비
mushroom<- read.csv (file = 'mlwr/mushrooms.csv',
encoding = 'UTF-8',stringsAsFactors = T)
# veil_type 변수(특징)는 모든 관찰값에서 항상 같은 값('partial')
# -> 버섯 분류할 때 사용되지 않는 변수 -> 데이터 프레임에서 제거
mushroom$veil_type <- NULL
# 버섯들의 클래스(분류 레이블) - type 변수
table(mushroom$type)
prop.table(table(mushroom$type))
# 버섯 분류 - 나이브 베이즈 방법
rm(list = ls())
# 1. 데이터 준비
mushroom<- read.csv (file = 'mlwr/mushrooms.csv',
encoding = 'UTF-8',stringsAsFactors = T)
# 나이브 베이즈 방법을 사용할 학습 데이터 세트 / 테스트 데이터 세트
# 학습(75%) : 테스트(25%)
sample_count<- nrow(mushroom)
# 나이브 베이즈 방법을 사용할 학습 데이터 세트 / 테스트 데이터 세트
# 학습(75%) : 테스트(25%)
sample_count<- nrow(mushroom) * 0.75
# 나이브 베이즈 방법을 사용할 학습 데이터 세트 / 테스트 데이터 세트
# 학습(75%) : 테스트(25%)
sample_count<- round(nrow(mushroom) * 0.75)
# nrow(데이터프레임) : 데이터프레임의 행(row, observation)의 갯수
# round(): 반올림 함수
set.seed(123)
sample_rows <- sample(nrow(mushroom),sample_count)
sample_rows
set.seed(123) # 같은 순서의 난수들을 발생시키기 위함( ex:선생님과 학생들 )
sample_rows <- sample(nrow(mushroom),sample_count)
sample_rows
# 학습 데이터 세트
mushroom_train <- mushroom[sample_rows,]
# 테스트 데이터 세트
mushroom_test <- mushroom[-sample_rows,]
train_label <- mushroom_train[sample_rows,]
test_label <- mushroom_train[-sample_rows,]
str(mushroom_train)
str(mushroom_test)
mushroom_train <- mushroom_train[-1]
str(mushroom_train)
str(mushroom_train)
mushroom_train <- mushroom_train[-1] # 첫 번째 컬럼(type)을 제거 !!
str(mushroom_train)
head(mushroom_train)
head(mushroom)
table(train_label)
table(train_label)
head(train_label)
train_label <- mushroom_train[sample_rows,1]
# 학습 데이터 세트
mushroom_train <- mushroom[sample_rows,]
train_label <- mushroom_train[sample_rows,1]
mushroom_train <- mushroom_train[-1] # 첫 번째 컬럼(type)을 제거 !!
# 테스트 데이터 세트
mushroom_test <- mushroom[-sample_rows,]
test_label <- mushroom_train[-sample_rows,1]
str(mushroom_train)
str(mushroom_test)
table(test_label)
table(train_label)
# 1. 데이터 준비
mushroom<- read.csv (file = 'mlwr/mushrooms.csv',
encoding = 'UTF-8',stringsAsFactors = T)
# veil_type 변수(특징)는 모든 관찰값에서 항상 같은 값('partial')
# -> 버섯 분류할 때 사용되지 않는 변수 -> 데이터 프레임에서 제거
mushroom$veil_type <- NULL
prop.table(table(mushroom$type))
# 나이브 베이즈 방법을 사용할 학습 데이터 세트 / 테스트 데이터 세트
# 학습(75%) : 테스트(25%)
sample_count<- round(nrow(mushroom) * 0.75)
sample_rows <- sample(nrow(mushroom),sample_count)
sample_rows
# 학습 데이터 세트
mushroom_train <- mushroom[sample_rows,]
train_label <- mushroom_train[sample_rows,1]
mushroom_train <- mushroom_train[-1] # 첫 번째 컬럼(type)을 제거 !!
# 테스트 데이터 세트
mushroom_test <- mushroom[-sample_rows,]
test_label <- mushroom_train[-sample_rows,1]
mushroom_test <- mushroom_test[-1]
head(train_label)
table(train_label)
head(test_label)
# 테스트 데이터 세트
mushroom_test <- mushroom[-sample_rows,]
head(mushroom_test)
test_label <- mushroom_train[-sample_rows,1]
head(test_label)
str(mushroom_test)
test_label <- mushroom_train[-sample_rows,1]
test_label <- mushroom_test[-sample_rows,1]
head(test_label)
mushroom_test <- mushroom_test[-1]
str(mushroom_train)
# 3 모델 생성 - 나이브 베이즈
library(e1071)
classifier <- naiveBayes(mushroom_train, train_label)
summary(cclassifier)
summary(classifier)
# 4 모델 평가
mushroom_predict <- predict(classifier, mushroom_test)
library(gmodels)
CrossTable(x= test_label, y= mushroom_predict)
CrossTable(x= test_label, y= mushroom_predict,
prop.chisq = F)
str(test_label)
test_label
mushroom_test
# 테스트 데이터 세트
mushroom_test <- mushroom[-sample_rows,]
test_label <- mushroom_test[-sample_rows,1]
mushroom_test <- mushroom_test[-1]
# 4 모델 평가
mushroom_predict <- predict(classifier, mushroom_test)
library(gmodels) #크로스 테이블 패키지
CrossTable(x= test_label, y= mushroom_predict,
prop.chisq = F)
# 테스트 데이터 세트
mushroom_test <- mushroom[-sample_rows, ]
test_label <- mushroom_test$type
mushroom_test <- mushroom_test[-1]
classifier <- naiveBayes(mushroom_train, train_label)
summary(classifier)
# 4. 모델 평가
mushroom_predict <- predict(classifier, mushroom_test)
CrossTable(x = test_label, y = mushroom_predict,
prop.chisq = F)
# 5 모델 향상 - 라플라스 추정량 변경
classifier <- naiveBayes(mushroom_train, train_label,
laplace = 1)
mushroom_predict < - predict(classifier, mushroom_test)
mushroom_predict < - predict(classifier, mushroom_test)
# 5 모델 향상 - 라플라스 추정량 변경
classifier <- naiveBayes(mushroom_train, train_label,
laplace = 1)
mushroom_predict < - predict(classifier, mushroom_test)
mushroom_predict <- predict(classifier, mushroom_test)
CrossTable(x= test_label, y = mushroom_predict,
prop.chisq = F)
# 4. 모델 평가
mushroom_predict <- predict(classifier, mushroom_test)
CrossTable(x = test_label, y = mushroom_predict,
prop.chisq = F)
# 5 모델 향상 - 라플라스 추정량 변경
classifier <- naiveBayes(mushroom_train, train_label,
laplace = 1)
mushroom_predict <- predict(classifier, mushroom_test)
CrossTable(x= test_label, y = mushroom_predict,
prop.chisq = F)
rm(list = ls())
# 데이터 준비
heights <- read.csv('mlwr/heights.csv')
head(heights)
# 아버지 키(father)의 분포
summary(heights)
heights(heights$father)
hist(heights$father)
hist(heights$son)
boxplot(heights$father)
# 산점도 그래프(scatter plot)
plot(heights)
# 산점도 그래프(scatter plot)
plot(heights, color = rgb(0.7,0.2,0.2,0.5))
# 산점도 그래프(scatter plot)
plot(heights, color = rgb(0.7,0.2,0.2))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.2,0.5))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(1,0.2,0.2,0.5))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.2,0.5))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.2,1))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.8,0.5))
2
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.2,0.5))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(1,,0.2,0.5))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(1,0,0.2,0.5))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(1,0,0.2,1))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(1,0,1,1))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(1,1,1,1))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(1,0.9,1,1))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(1,0.1,1,1))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.5,0.5,0.5,1))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.5,0.5,0.4,1))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.5,0.5,0.4,0.5))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.4,0.5))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.7,0.5))
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.7,0.9))
abline(h = mean(heights$son))
#abline(): 보조선, h : 수평보조선, v : 수직 보조선
abline(v = mean(heights$father),lty = 2)
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.7,0.9))
#abline(): 보조선, h : 수평보조선, v : 수직 보조선
abline(v = mean(heights$father),lty = 2)
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.7,0.9))
#abline(): 보조선, h : 수평보조선, v : 수직 보조선
abline(v = mean(heights$father),lty = 2)
abline(h = mean(heights$son)) #h = horizontal 가로 보조선
#lm() 함수 : linear regression model(선형 회귀 모델)
lm_heights <- lm(formula = son ~ father, data = heights)
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.7,0.9))
#abline(): 보조선, h : 수평보조선, v : 수직 보조선
abline(v = mean(heights$father),lty = 2)
lm_heights
summary(lm_heights)
# 선형 모델에서 찾은 coefficient(계수)들을 이용해서
# 선형 모델 그래프를 추가
abline()
# 선형 모델에서 찾은 coefficient(계수)들을 이용해서
# 선형 모델 그래프를 추가
abline(a = 86.10257, b = 0.51391)
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.7,0.9))
# 선형 모델에서 찾은 coefficient(계수)들을 이용해서
# 선형 모델 그래프를 추가
abline(a = 86.10257, b = 0.51391)
# ggplot2를 이용한 그래프
library(ggplot2)
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point()
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(fill = red)
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = red)
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = 'red')
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5))
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son))
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed')
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')+
geom_vline(xintercept = mean(heights$father),
linetype = 'dahsed', color = 'darkblue')
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')+
geom_vline(xintercept = mean(heights$father),
linetype = 'dahsed', color = 'darkblue')
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')+
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')
# ggplot2를 이용한 그래프
library(ggplot2)
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')+
geom_vline(xintercept = mean(heights$father),
linetype = 'dahsed', color = 'darkblue')
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')+
geom_vline(xintercept = mean(heights$father),
linetype = 'dahsed', color = 'darkblue')  +
stat_smooth(method = 'lm')
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')+
stat_smooth(method = 'lm')
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')+
geom_vline(xintercept = mean(heights$father),
linetype = 'dashed', color = 'darkblue')+
stat_smooth(method = 'lm')
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')+
geom_vline(xintercept = mean(heights$father),
linetype = 'dashed', color = 'darkblue') # 흐린 부분들은 잔차들의 오차범위
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')+
geom_vline(xintercept = mean(heights$father),
linetype = 'dashed', color = 'darkblue')+
stat_smooth(method = 'lm')  # 흐린 부분들은 잔차들의 오차범위
# 선형 회귀 모델식 : y = a + bx
# a = mean(y) - b * mean(x)
# 선형 회귀 모델식은 점 (x의평균,y의평균)을 지나가는 점이다.
# b = Cov(x,y) / Var(x)
m_x <- mean(heights$father)
m_y <- mean(heights$son)
cov_xy <- cov(heights$father, heights$son)
var_x <- var(heights$father)
b <- cov_xy/ var_x
a <- m_y-b*m_x
#Pearson's correlation Coefficient( 상관계수 )
cor(heights$father, heights$son)
# 챌린저호의 사고 조사 데이터!!
launch <- read.csv(file = 'mlwr/challenger.csv')
rm(list = ls())
# 챌린저호의 사고 조사 데이터!!
launch <- read.csv(file = 'mlwr/challenger.csv')
str(launch)
head(launch)
summary(launc)
summary(launch)
# 단순 선형 회귀(distress_ct ~ temperature)
plot(x = launch$temperature, y = launch$distress_ct)
lm_launch <- lm(formula=distress_ct ~ temperature, data = launch )
summary(lm_launch)
a <- lm_launch$coefficients[1] # 선형모델의 y절편
a
b <- lm_launch$coefficients[2] # 선형 모델의 기울기
b
abline(a= a, b= b, col= 'blue')
# 다중선형 회귀(multiple linear regression
# y ~ x1 + x2 + x3 + ...
str(launch)
lm_launch <- lm(formula = distress_ct ~ ., data= launch )
summary(lm_launch)
rm(list= ls())
insurance = read.csv('mlwr/insurance.csv')
# 데이터 확인
str(insurance)
# BMI(Body-Mass Index) =
summary(insurance)
# 데이터 확인
str(insurance)
# BMI(Body-Mass Index) =
summary(insurance)
# 종속 변수- expenses(의료비 지출)
boxplot(insurance$expenses)
hist(insurance$expenses)
# 상관 계수: cor(x, y)
cor(insurance$bmi, insurance$expenses)
# 상관 행렬 : 상관 계수들로 만든 행렬
cor(insurance[c('age', 'bmi', 'children', 'expenses')])
pairs(insurance[c('age', 'bmi', 'children', 'expenses')])
install.packages(psych)
install.packages('psych')
library(psych)
pairs.panels(insurance[c('age', 'bmi', 'children', 'expenses')])
pairs.panels(insurance)
# 다중 선형 회귀 (multiple linear regression)
# expenses ~ 나머지 모든 변수
ins_model <- lm(formula = expenses~., data = insurance)
ins_model
summary(ins_model)
# 선형 회귀 모델을 수정해서 모델 성능 향상 !!
# 나이의 비선형 항을 추가
insurance$age2 <- insurance$age^2
head(insurance$age2)
head(insurance[c('age', 'age2')])
# 수치형 변수를 이진화
# bmi 값이 30 이상이면 1, 그렇지 않으면 0으로 변환
insurance$bmi30 <- ifelse(insurance$bmi>30, 1, 0)
head(insurance$bmi30)
head(insurance[c('bmi','bmi30')])
# 두 변수 이상의 상호작용을 선형 회귀 모델에 추가
# 흡연 + 비만
structure(insurance)
ins_model2 <- lm(formula = expenses~ age + sex + bmi +
chileren + smoker + region+ age2 + bmi30+
smoker*bmi30,
data = insurance)
ins_model2 <- lm(formula = expenses~ age + sex + bmi +
children + smoker + region+ age2 + bmi30+
smoker*bmi30,
data = insurance)
summary(ins_model2)
rm(list= ls())
insurance = read.csv('mlwr/insurance.csv')
rm(list = ls())
# 데이터 준비
heights <- read.csv('mlwr/heights.csv')
head(heights)
head(heights)
# 아버지 키(father)의 분포
summary(heights)
hist(heights$father)
boxplot(heights$father)
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.7,0.9))
abline(h = mean(heights$son)) #h = horizontal 가로 보조선
# 산점도 그래프(scatter plot)
plot(heights, col = rgb(0.7,0.2,0.7,0.9))
#abline(): 보조선, h : 수평보조선, v : 수직 보조선
abline(v = mean(heights$father),lty = 2)
#lm() 함수 : linear regression model(선형 회귀 모델)
lm_heights <- lm(formula = son ~ father, data = heights) # formula = 종속변수 ~ 독립변수
summary(lm_heights)
# 선형 모델에서 찾은 coefficient(계수)들을 이용해서
# 선형 모델 그래프를 추가
abline(a = 86.10257, b = 0.51391)
# ggplot2를 이용한 그래프
library(ggplot2)
ggplot(data = heights, mapping = aes(x = father, y = son)) +
geom_point(color = rgb(0.7,0.2,0.5,0.5))+
geom_hline(yintercept = mean(heights$son),
linetype = 'dashed', color = 'darkblue')+
geom_vline(xintercept = mean(heights$father),
linetype = 'dashed', color = 'darkblue')+
stat_smooth(method = 'lm')  # 흐린 부분들은 잔차들의 오차범위
insurance = read.csv('mlwr/insurance.csv')
rm(list= ls())
insurance = read.csv('mlwr/insurance.csv')
# 다중 선형 회귀 (multiple linear regression)
# expenses ~ 나머지 모든 변수
ins_model <- lm(formula = expenses~., data = insurance)
# 수치형 변수를 이진화
# bmi 값이 30 이상이면 1, 그렇지 않으면 0으로 변환
insurance$bmi30 <- ifelse(insurance$bmi>30, 1, 0)
ins_model2 <- lm(formula = expenses~ age + sex + bmi +
children + smoker + region+ age2 + bmi30+
smoker*bmi30,
data = insurance)
# 상관 행렬 : 상관 계수들로 만든 행렬
cor(insurance[c('age', 'bmi', 'children', 'expenses')])
pairs(insurance[c('age', 'bmi', 'children', 'expenses')])
# 다중 선형 회귀 (multiple linear regression)
# expenses ~ 나머지 모든 변수
ins_model <- lm(formula = expenses~., data = insurance)
ins_model
summary(ins_model)
head(insurance[c('age', 'age2')])
